{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7653641,"sourceType":"datasetVersion","datasetId":4462011}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nimport spacy\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport matplotlib.pyplot as plt\nfrom transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T03:33:20.564159Z","iopub.execute_input":"2024-02-21T03:33:20.564616Z","iopub.status.idle":"2024-02-21T03:33:39.547493Z","shell.execute_reply.started":"2024-02-21T03:33:20.564571Z","shell.execute_reply":"2024-02-21T03:33:39.546585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Read the input CSV file into a pandas DataFrame with the correct delimiter\ndf = pd.read_csv('/kaggle/input/my-dataset/QA_dataset.csv')\ndf = df.sample(frac = 1)\ndf = df.reset_index(drop=True)\n\n# Initialize an empty DataFrame for transformed data\ndata = pd.DataFrame(columns=['context', 'question', 'answer'])\n\nframes = []\n\n# Iterate through each row and transform the data\nfor _, row in df.iterrows():\n    paragraph = row['Paragraphs']\n    temp_df = pd.DataFrame({\n        'context': [paragraph] * 3,\n        'question': [row[f'Question{i}'] for i in range(1, 4)],\n        'answer': [row[f'Answer{i}'] for i in range(1, 4)]\n    })\n    \n    frames.append(temp_df)\n\n# Concatenate the list of DataFrames\ndata = pd.concat(frames, ignore_index=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T03:33:39.549775Z","iopub.execute_input":"2024-02-21T03:33:39.550743Z","iopub.status.idle":"2024-02-21T03:33:41.342040Z","shell.execute_reply.started":"2024-02-21T03:33:39.550707Z","shell.execute_reply":"2024-02-21T03:33:41.341235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.iloc[0:1000,:]","metadata":{"execution":{"iopub.status.busy":"2024-02-21T03:33:41.343576Z","iopub.execute_input":"2024-02-21T03:33:41.343865Z","iopub.status.idle":"2024-02-21T03:33:41.348085Z","shell.execute_reply.started":"2024-02-21T03:33:41.343841Z","shell.execute_reply":"2024-02-21T03:33:41.347158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-02-21T03:33:41.349346Z","iopub.execute_input":"2024-02-21T03:33:41.349612Z","iopub.status.idle":"2024-02-21T03:33:41.372923Z","shell.execute_reply.started":"2024-02-21T03:33:41.349589Z","shell.execute_reply":"2024-02-21T03:33:41.372000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q_LEN = 256   # Question Length\nT_LEN = 32    # Target Length\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nEPOCHS = 15","metadata":{"execution":{"iopub.status.busy":"2024-02-21T03:33:41.374986Z","iopub.execute_input":"2024-02-21T03:33:41.375264Z","iopub.status.idle":"2024-02-21T03:33:41.380256Z","shell.execute_reply.started":"2024-02-21T03:33:41.375240Z","shell.execute_reply":"2024-02-21T03:33:41.379253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T03:33:41.381439Z","iopub.execute_input":"2024-02-21T03:33:41.381762Z","iopub.status.idle":"2024-02-21T03:33:42.239714Z","shell.execute_reply.started":"2024-02-21T03:33:41.381733Z","shell.execute_reply":"2024-02-21T03:33:42.238944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_qa_data(tokenizer, dataframe, q_len, t_len):\n    questions = dataframe[\"question\"]\n    context = dataframe[\"context\"]\n    answer = dataframe['answer']\n\n    qa_data = []\n\n    for idx in range(len(questions)):\n        question = questions[idx]\n        context_text = context[idx]\n        answer_text = answer[idx]\n\n        question_tokenized = tokenizer(question, context_text, max_length=q_len, padding=\"max_length\",\n                                       truncation=True, pad_to_max_length=True, add_special_tokens=True)\n        answer_tokenized = tokenizer(answer_text, max_length=t_len, padding=\"max_length\",\n                                     truncation=True, pad_to_max_length=True, add_special_tokens=True)\n\n        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n        labels[labels == 0] = -100\n\n        qa_data.append({\n            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n            \"labels\": labels,\n            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n        })\n\n    return qa_data\n\ndef create_loaders(tokenizer, data, q_len, t_len, batch_size, train_data, val_data):\n\n    train_sampler = RandomSampler(train_data.index)\n    val_sampler = RandomSampler(val_data.index)\n\n    qa_data = prepare_qa_data(tokenizer, data, q_len, t_len)\n\n    train_loader = DataLoader(qa_data, batch_size=batch_size, sampler=train_sampler)\n    val_loader = DataLoader(qa_data, batch_size=batch_size, sampler=val_sampler)\n\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2024-02-21T03:33:42.240822Z","iopub.execute_input":"2024-02-21T03:33:42.241108Z","iopub.status.idle":"2024-02-21T03:33:42.252290Z","shell.execute_reply.started":"2024-02-21T03:33:42.241085Z","shell.execute_reply":"2024-02-21T03:33:42.251166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Initialize KFold cross-validator\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ndata.reset_index(drop=True, inplace=True)\n\n# Initialize list of lists to store validation losses for each fold\nvalidation_losses_per_fold = [[] for _ in range(kf.n_splits)]\ntrain_losses_per_fold = [[] for _ in range(kf.n_splits)]\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(data), 1):\n    print(f\"Fold #{fold}\")\n\n    # Prepare dataset\n    train_dataset = data.iloc[train_idx]\n    test_dataset = data.iloc[test_idx]\n    \n    # Create DataLoader\n    train_loader, test_loader = create_loaders(TOKENIZER, data, Q_LEN, T_LEN, BATCH_SIZE, train_dataset,test_dataset)\n\n    \n    # Create the model and move it to the appropriate device\n    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n\n\n    # Define optimizer\n    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n\n    # Training loop\n    for epoch in range(EPOCHS):\n        model.train()\n        train_loss = 0.0\n        total_samples = 0\n        for batch in tqdm(train_loader, desc=\"Training batches\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels,\n                decoder_attention_mask=decoder_attention_mask\n            )\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * len(input_ids)\n            total_samples += len(input_ids)\n\n        # Store average training loss for current epoch\n        train_loss /= total_samples\n        train_losses_per_fold[fold - 1].append(train_loss)\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_loss = 0.0\n            total_samples = 0\n            for batch in tqdm(test_loader, desc=\"Validation batches\"):\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n                labels = batch[\"labels\"].to(device)\n                decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n\n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels,\n                    decoder_attention_mask=decoder_attention_mask\n                )\n                val_loss += outputs.loss.item() * len(input_ids)\n                total_samples += len(input_ids)\n            \n            val_loss /= total_samples\n\n        # Store validation loss for current fold and epoch\n        validation_losses_per_fold[fold - 1].append(val_loss)\n        print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n\n    print(\"Training completed for fold.\\n\")\n    \n# Plot training vs validation loss for each fold\nplt.figure(figsize=(10, 6))\nfor fold, (train_losses, val_losses) in enumerate(zip(train_losses_per_fold, validation_losses_per_fold), 1):\n    plt.plot(range(1, EPOCHS + 1), train_losses, label=f\"Fold {fold} Train\")\n    plt.plot(range(1, EPOCHS + 1), val_losses, label=f\"Fold {fold} Validation\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training vs Validation Loss\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T03:33:42.253889Z","iopub.execute_input":"2024-02-21T03:33:42.254136Z","iopub.status.idle":"2024-02-21T04:42:30.467320Z","shell.execute_reply.started":"2024-02-21T03:33:42.254117Z","shell.execute_reply":"2024-02-21T04:42:30.466267Z"},"trusted":true},"execution_count":null,"outputs":[]}]}