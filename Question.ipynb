{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7653641,"sourceType":"datasetVersion","datasetId":4462011}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nimport spacy\nfrom sklearn.model_selection import KFold\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport matplotlib.pyplot as plt\nfrom transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-20T16:04:43.164575Z","iopub.execute_input":"2024-02-20T16:04:43.164973Z","iopub.status.idle":"2024-02-20T16:04:54.940847Z","shell.execute_reply.started":"2024-02-20T16:04:43.164936Z","shell.execute_reply":"2024-02-20T16:04:54.939987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Read the input CSV file into a pandas DataFrame with the correct delimiter\ndf = pd.read_csv('/kaggle/input/my-dataset/QA_dataset.csv')\ndf = df.sample(frac = 1)\ndf = df.reset_index(drop=True)\n\n# Initialize an empty DataFrame for transformed data\ndata = pd.DataFrame(columns=['context', 'question', 'answer'])\n\nframes = []\n\n# Iterate through each row and transform the data\nfor _, row in df.iterrows():\n    paragraph = row['Paragraphs']\n    temp_df = pd.DataFrame({\n        'context': [paragraph] * 3,\n        'question': [row[f'Question{i}'] for i in range(1, 4)],\n        'answer': [row[f'Answer{i}'] for i in range(1, 4)]\n    })\n    \n    frames.append(temp_df)\n\n# Concatenate the list of DataFrames\ndata = pd.concat(frames, ignore_index=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T16:04:54.942652Z","iopub.execute_input":"2024-02-20T16:04:54.943362Z","iopub.status.idle":"2024-02-20T16:04:56.724432Z","shell.execute_reply.started":"2024-02-20T16:04:54.943326Z","shell.execute_reply":"2024-02-20T16:04:56.723638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata = data.iloc[0:1000,:]","metadata":{"execution":{"iopub.status.busy":"2024-02-20T16:04:56.725645Z","iopub.execute_input":"2024-02-20T16:04:56.725994Z","iopub.status.idle":"2024-02-20T16:04:56.730898Z","shell.execute_reply.started":"2024-02-20T16:04:56.725963Z","shell.execute_reply":"2024-02-20T16:04:56.729946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-02-20T16:04:56.732792Z","iopub.execute_input":"2024-02-20T16:04:56.733059Z","iopub.status.idle":"2024-02-20T16:04:56.754153Z","shell.execute_reply.started":"2024-02-20T16:04:56.733037Z","shell.execute_reply":"2024-02-20T16:04:56.753303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q_LEN = 256   # Question Length\nT_LEN = 32    # Target Length\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nEPOCHS = 15","metadata":{"execution":{"iopub.status.busy":"2024-02-20T16:04:56.755066Z","iopub.execute_input":"2024-02-20T16:04:56.755323Z","iopub.status.idle":"2024-02-20T16:04:56.759787Z","shell.execute_reply.started":"2024-02-20T16:04:56.755300Z","shell.execute_reply":"2024-02-20T16:04:56.758719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TOKENIZER = T5TokenizerFast.from_pretrained(\"t5-base\")\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T16:04:56.760898Z","iopub.execute_input":"2024-02-20T16:04:56.761186Z","iopub.status.idle":"2024-02-20T16:04:57.922297Z","shell.execute_reply.started":"2024-02-20T16:04:56.761163Z","shell.execute_reply":"2024-02-20T16:04:57.921323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_qa_data(tokenizer, dataframe, q_len, t_len):\n    questions = dataframe[\"question\"]\n    context = dataframe[\"context\"]\n    answer = dataframe['answer']\n\n    qa_data = []\n\n    for idx in range(len(questions)):\n        question = questions[idx]\n        context_text = context[idx]\n        answer_text = answer[idx]\n\n        context_tokenized = tokenizer(context_text, max_length=q_len, padding=\"max_length\",\n                                       truncation=True, pad_to_max_length=True, add_special_tokens=True)\n        question_tokenized = tokenizer(question, max_length=t_len, padding=\"max_length\",\n                                     truncation=True, pad_to_max_length=True, add_special_tokens=True)\n\n        labels = torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long)\n        labels[labels == 0] = -100\n\n        qa_data.append({\n            \"input_ids\": torch.tensor(context_tokenized[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(context_tokenized[\"attention_mask\"], dtype=torch.long),\n            \"labels\": labels,\n            \"decoder_attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long)\n        })\n\n    return qa_data\n\ndef create_loaders(tokenizer, data, q_len, t_len, batch_size, train_data, val_data):\n\n    train_sampler = RandomSampler(train_data.index)\n    val_sampler = RandomSampler(val_data.index)\n\n    qa_data = prepare_qa_data(tokenizer, data, q_len, t_len)\n\n    train_loader = DataLoader(qa_data, batch_size=batch_size, sampler=train_sampler)\n    val_loader = DataLoader(qa_data, batch_size=batch_size, sampler=val_sampler)\n\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2024-02-20T16:04:57.923546Z","iopub.execute_input":"2024-02-20T16:04:57.923865Z","iopub.status.idle":"2024-02-20T16:04:57.935383Z","shell.execute_reply.started":"2024-02-20T16:04:57.923826Z","shell.execute_reply":"2024-02-20T16:04:57.934686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Initialize KFold cross-validator\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ndata.reset_index(drop=True, inplace=True)\n\n# Initialize list of lists to store validation losses for each fold\nvalidation_losses_per_fold = [[] for _ in range(kf.n_splits)]\ntrain_losses_per_fold = [[] for _ in range(kf.n_splits)]\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(data), 1):\n    print(f\"Fold #{fold}\")\n\n    # Prepare dataset\n    train_dataset = data.iloc[train_idx]\n    test_dataset = data.iloc[test_idx]\n\n    # Create DataLoader\n    train_loader, test_loader = create_loaders(TOKENIZER, data, Q_LEN, T_LEN, BATCH_SIZE, train_dataset,test_dataset)\n    # Create the model and move it to the appropriate device\n    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n\n\n    # Define optimizer\n    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n\n    # Training loop\n    for epoch in range(EPOCHS):\n        model.train()\n        train_loss = 0.0\n        total_samples = 0\n        for batch in tqdm(train_loader, desc=\"Training batches\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels,\n                decoder_attention_mask=decoder_attention_mask\n            )\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * len(input_ids)\n            total_samples += len(input_ids)\n\n        # Store average training loss for current epoch\n        train_loss /= total_samples\n        train_losses_per_fold[fold - 1].append(train_loss)\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_loss = 0.0\n            total_samples = 0\n            for batch in tqdm(test_loader, desc=\"Validation batches\"):\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n                labels = batch[\"labels\"].to(device)\n                decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n\n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels,\n                    decoder_attention_mask=decoder_attention_mask\n                )\n                val_loss += outputs.loss.item() * len(input_ids)\n                total_samples += len(input_ids)\n            \n            val_loss /= total_samples\n\n        # Store validation loss for current fold and epoch\n        validation_losses_per_fold[fold - 1].append(val_loss)\n        print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n\n    print(\"Training completed for fold.\\n\")\n    \n# Plot training vs validation loss for each fold\nplt.figure(figsize=(10, 6))\nfor fold, (train_losses, val_losses) in enumerate(zip(train_losses_per_fold, validation_losses_per_fold), 1):\n    plt.plot(range(1, EPOCHS + 1), train_losses, label=f\"Fold {fold} Train\")\n    plt.plot(range(1, EPOCHS + 1), val_losses, label=f\"Fold {fold} Validation\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training vs Validation Loss\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-20T16:04:57.937057Z","iopub.execute_input":"2024-02-20T16:04:57.937406Z","iopub.status.idle":"2024-02-20T16:41:50.904157Z","shell.execute_reply.started":"2024-02-20T16:04:57.937374Z","shell.execute_reply":"2024-02-20T16:41:50.903153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}